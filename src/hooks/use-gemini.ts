import { useEffect, useState, useCallback, useRef } from "react"

// Chrome Built-in AI íƒ€ì…ì€ src/global.d.tsì—ì„œ ì „ì—­ ì„ ì–¸ë¨
// https://github.com/webmachinelearning/prompt-api

export type AIStatus = "loading" | "ready" | "downloading" | "error" | "unsupported"

/**
 * AI API ì°¾ê¸° (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
 * íƒ€ì…ì€ global.d.tsì—ì„œ ì „ì—­ ì„ ì–¸ë˜ì–´ @ts-ignore ë¶ˆí•„ìš”
 */
const getLanguageModel = (): LanguageModelAPI | null => {
  // 1. ì „ì—­ LanguageModel ê°ì²´ í™•ì¸ (ìµœì‹  ìŠ¤í™)
  if (typeof LanguageModel !== "undefined") {
    return LanguageModel
  }
  // 2. window.ai.languageModel í™•ì¸ (ë ˆê±°ì‹œ í˜¸í™˜)
  if (typeof window !== "undefined" && window.ai?.languageModel) {
    return window.ai.languageModel
  }
  // 3. self.ai.languageModel í™•ì¸ (Service Worker í™˜ê²½)
  if (typeof self !== "undefined" && self.ai?.languageModel) {
    return self.ai.languageModel
  }
  return null
}

export const useGemini = () => {
  const [status, setStatus] = useState<AIStatus>("loading")
  const [downloadProgress, setDownloadProgress] = useState<number>(0)
  const sessionRef = useRef<LanguageModelSession | null>(null)
  const abortControllerRef = useRef<AbortController | null>(null)

  useEffect(() => {
    const initModel = async () => {
      try {
        abortControllerRef.current = new AbortController()

        // 1. API ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        const languageModel = getLanguageModel()

        console.log("ğŸ” Checking AI API...")

        if (!languageModel) {
          console.error("âŒ Chrome AI API not found. Please check:")
          console.error("1. Use Chrome Canary or Dev (version 131+)")
          console.error("2. Enable chrome://flags/#optimization-guide-on-device-model")
          console.error("3. Enable chrome://flags/#prompt-api-for-gemini-nano")
          setStatus("error")
          return
        }

        console.log("âœ… AI API found")

        // 2. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ (ìµœì‹  API: availability())
        const availability = await languageModel.availability()
        console.log("ğŸ“Š Model Availability:", availability)

        if (availability === "unavailable") {
          console.error("âŒ Model not available on this device")
          setStatus("unsupported")
          return
        }

        if (availability === "downloadable" || availability === "downloading") {
          setStatus("downloading")
        }

        // 3. ëª¨ë¸ íŒŒë¼ë¯¸í„° í™•ì¸ (ì„ íƒì‚¬í•­)
        const params = await languageModel.params()
        if (params) {
          console.log("ğŸ“Š Model Params:", params)
        }

        console.log("ğŸš€ Creating AI session...")

        // 4. ì„¸ì…˜ ìƒì„± (ìµœì‹  API ìŠ¤í™ - 2026) + 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        const createSessionPromise = languageModel.create({
          // initialPromptsë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
          initialPrompts: [
            {
              role: "system",
              content:
                "ë‹¹ì‹ ì€ 'Memex'ë¼ëŠ” ì´ë¦„ì˜ ìœ ëŠ¥í•œ ë¡œì»¬ AI ë¹„ì„œì…ë‹ˆë‹¤. " +
                "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. " +
                "ë‹µë³€ì€ ëª…í™•í•˜ê³  ì¹œì ˆí•´ì•¼ í•˜ë©°, ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }
          ],
          // ì¶œë ¥ ì–¸ì–´ ì„¤ì • (Chrome AI Safety Check í•„ìˆ˜)
          // ì§€ì› ì–¸ì–´: en, es, ja (ko ë¯¸ì§€ì› - systemPromptë¡œ í•œêµ­ì–´ ì‘ë‹µ ìœ ë„)
          expectedOutputs: [
            { type: "text", languages: ["en"] }
          ],
          // AbortSignal ì „ë‹¬
          signal: abortControllerRef.current.signal,
          // ë‹¤ìš´ë¡œë“œ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§
          monitor: (monitor) => {
            monitor.addEventListener("downloadprogress", (event) => {
              const progress = Math.round(event.loaded * 100)
              console.log(`ğŸ“¥ Download progress: ${progress}%`)
              setDownloadProgress(progress)
            })
          }
        })

        // íƒ€ì„ì•„ì›ƒ (30ì´ˆ) - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì ìš©
        const timeoutPromise = new Promise<never>((_, reject) => {
          setTimeout(() => {
            reject(new Error("AI ì„¸ì…˜ ìƒì„± ì‹œê°„ ì´ˆê³¼ (30ì´ˆ). Chromeì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."))
          }, 30000)
        })

        const newSession = await Promise.race([createSessionPromise, timeoutPromise])

        sessionRef.current = newSession
        setStatus("ready")

        // ì„¸ì…˜ ì •ë³´ ë¡œê¹…
        console.log(`âœ… Session ready. Usage: ${newSession.inputUsage}/${newSession.inputQuota} tokens`)

        // Quota overflow ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        newSession.addEventListener("quotaoverflow", () => {
          console.warn("âš ï¸ Context window exceeded; old messages may be removed")
        })

      } catch (e) {
        console.error("AI Initialization Failed:", e)
        setStatus("error")
      }
    }

    initModel()

    // Cleanup: ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì„¸ì…˜ ì •ë¦¬
    return () => {
      if (abortControllerRef.current) {
        abortControllerRef.current.abort()
      }
      if (sessionRef.current) {
        try {
          sessionRef.current.destroy()
        } catch (e) {
          // ignore error
        }
      }
    }
  }, [])

  // ë‹µë³€ ìƒì„± í•¨ìˆ˜
  const generate = useCallback(
    async (input: string, options?: { signal?: AbortSignal }) => {
      if (!sessionRef.current || status !== "ready") {
        throw new Error("AI ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
      }
      try {
        const response = await sessionRef.current.prompt(input, {
          signal: options?.signal
        })
        return response
      } catch (e) {
        if (e instanceof Error && e.name === "AbortError") {
          return "ìš”ì²­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        console.error("Generation Error:", e)
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
      }
    },
    [status]
  )

  // ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± í•¨ìˆ˜ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
  const generateStream = useCallback(
    (input: string, options?: { signal?: AbortSignal; image?: string }) => {
      if (!sessionRef.current || status !== "ready") {
        throw new Error("AI ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
      }

      // ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
      if (options?.image) {
        // Base64 ë°ì´í„° URLì—ì„œ Blob ìƒì„±
        const base64Data = options.image.split(",")[1]
        const mimeType = options.image.split(";")[0].split(":")[1]
        const byteCharacters = atob(base64Data)
        const byteNumbers = new Array(byteCharacters.length)
        for (let i = 0; i < byteCharacters.length; i++) {
          byteNumbers[i] = byteCharacters.charCodeAt(i)
        }
        const byteArray = new Uint8Array(byteNumbers)
        const imageBlob = new Blob([byteArray], { type: mimeType })

        // ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ë°°ì—´
        const content: LanguageModelContent[] = [
          { type: "image", value: imageBlob },
          { type: "text", value: input }
        ]

        return sessionRef.current.promptStreaming(
          [{ role: "user", content }] as LanguageModelPrompt[],
          { signal: options?.signal }
        )
      }

      // í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
      return sessionRef.current.promptStreaming(input, {
        signal: options?.signal
      })
    },
    [status]
  )

  // í† í° ì‚¬ìš©ëŸ‰ ì¸¡ì •
  const measureTokens = useCallback(
    async (input: string) => {
      if (!sessionRef.current) return 0
      return await sessionRef.current.measureInputUsage(input)
    },
    []
  )

  // í˜„ì¬ ì„¸ì…˜ ì •ë³´
  const getSessionInfo = useCallback(() => {
    if (!sessionRef.current) return null
    return {
      inputUsage: sessionRef.current.inputUsage,
      inputQuota: sessionRef.current.inputQuota
    }
  }, [])

  return {
    status,
    downloadProgress,
    generate,
    generateStream,
    measureTokens,
    getSessionInfo
  }
}
